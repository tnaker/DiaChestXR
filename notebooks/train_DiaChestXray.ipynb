{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTCMLw9qRbL6",
        "outputId": "4e0730b0-656e-4997-daa7-9836209a4e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚è≥ ƒêang gi·∫£i n√©n... (Ch·ªù x√≠u nh√©)\n",
            "replace /content/processed/000434271f63a053c4128a0ba6352c7f.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "‚úÖ ƒê√£ gi·∫£i n√©n xong t·∫°i /content/data\n",
            "\n",
            "üöÄ B·∫ÆT ƒê·∫¶U TRAIN: ALEX\n",
            "‚úÖ Data Loaded: 6861 Train | 1716 Val\n",
            "üè∑Ô∏è Classes: ['COVID-19', 'Normal', 'Pneumonia']\n",
            "üèóÔ∏è Model: AlexNet\n",
            "Epoch 1: Loss=0.0597 | Val Acc=99.77%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/alex_best.pth\n",
            "Epoch 2: Loss=0.0229 | Val Acc=99.71%\n",
            "Epoch 3: Loss=0.0163 | Val Acc=99.71%\n",
            "Epoch 4: Loss=0.0169 | Val Acc=99.71%\n",
            "Epoch 5: Loss=0.0094 | Val Acc=99.59%\n",
            "Epoch 6: Loss=0.0087 | Val Acc=99.88%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/alex_best.pth\n",
            "Epoch 7: Loss=0.0096 | Val Acc=99.30%\n",
            "Epoch 8: Loss=0.0105 | Val Acc=99.88%\n",
            "Epoch 9: Loss=0.0078 | Val Acc=99.88%\n",
            "Epoch 10: Loss=0.0121 | Val Acc=99.65%\n",
            "Epoch 11: Loss=0.0077 | Val Acc=99.65%\n",
            "Epoch 12: Loss=0.0117 | Val Acc=99.83%\n",
            "Epoch 13: Loss=0.0068 | Val Acc=99.88%\n",
            "Epoch 14: Loss=0.0063 | Val Acc=99.94%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/alex_best.pth\n",
            "Epoch 15: Loss=0.0044 | Val Acc=99.88%\n",
            "\n",
            "üöÄ B·∫ÆT ƒê·∫¶U TRAIN: DENSE\n",
            "‚úÖ Data Loaded: 12000 Train | 3000 Val\n",
            "üè∑Ô∏è Classes: ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'No finding', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis']\n",
            "üèóÔ∏è Model: DenseNet121\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30.8M/30.8M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Loss=0.1954 | Val Acc=94.57%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/dense_best.pth\n",
            "Epoch 2: Loss=0.1340 | Val Acc=94.82%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/dense_best.pth\n",
            "Epoch 3: Loss=0.1200 | Val Acc=95.14%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/dense_best.pth\n",
            "Epoch 4: Loss=0.1104 | Val Acc=94.90%\n",
            "Epoch 5: Loss=0.1004 | Val Acc=95.26%\n",
            "   üíæ Saved Best Model: /content/drive/MyDrive/DiaChestXR_Project/dense_best.pth\n",
            "Epoch 6: Loss=0.0919 | Val Acc=95.20%\n",
            "Epoch 7: Loss=0.0844 | Val Acc=95.17%\n",
            "Epoch 8: Loss=0.0786 | Val Acc=95.21%\n",
            "Epoch 9: Loss=0.0689 | Val Acc=95.21%\n",
            "Epoch 10: Loss=0.0618 | Val Acc=95.01%\n",
            "Epoch 11: Loss=0.0530 | Val Acc=94.85%\n",
            "Epoch 12: Loss=0.0467 | Val Acc=95.26%\n",
            "Epoch 13: Loss=0.0404 | Val Acc=95.17%\n",
            "Epoch 14: Loss=0.0361 | Val Acc=95.17%\n",
            "Epoch 15: Loss=0.0306 | Val Acc=95.16%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/DiaChestXR_Project/processed.zip'\n",
        "\n",
        "if not os.path.exists('/content/data'):\n",
        "    print(\"Unzipping data...\")\n",
        "    !unzip -q \"$zip_path\" -d /content/\n",
        "    print(\"Unzip completed.\")\n",
        "else:\n",
        "    print(\"Data already unzipped.\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None, mode='dense'):\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "        self.classes = sorted(df['class_name'].unique())\n",
        "        self.c2i = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "        if mode == 'dense':\n",
        "            self.data = df.groupby('image_id')['class_name'].apply(list).reset_index()\n",
        "        else:\n",
        "            self.data = df\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == 'dense':\n",
        "            row = self.data.iloc[idx]\n",
        "            img_id = row['image_id']\n",
        "            labels = row['class_name']\n",
        "        else:\n",
        "            row = self.data.iloc[idx]\n",
        "            img_id = row['image_id']\n",
        "            label_name = row['class_name']\n",
        "\n",
        "        exts = ['.jpg', '.png', '.jpeg']\n",
        "        for ext in exts:\n",
        "            path = os.path.join(self.img_dir, str(img_id) + ext)\n",
        "            if os.path.exists(path):\n",
        "                img_path = path\n",
        "                break\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            image = Image.new('RGB', (227, 227))\n",
        "\n",
        "        if self.transform: image = self.transform(image)\n",
        "\n",
        "        if self.mode == 'dense':\n",
        "            target = torch.zeros(len(self.classes))\n",
        "            for cls in labels:\n",
        "                if cls in self.c2i: target[self.c2i[cls]] = 1.0\n",
        "        else:\n",
        "            target = torch.tensor(self.c2i[label_name], dtype=torch.long)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "# --- TRAINING ENGINE ---\n",
        "def train_on_colab(model_type, epochs=10):\n",
        "    print(f\"\\nStarting training: {model_type.upper()}\")\n",
        "\n",
        "\n",
        "    data_root = \"/content/processed\"\n",
        "    img_dir = f\"{data_root}\"\n",
        "    csv_train = f\"{data_root}/splits/train_{model_type}.csv\"\n",
        "    csv_val = f\"{data_root}/splits/val_{model_type}.csv\"\n",
        "\n",
        "    # Transform\n",
        "    tf = transforms.Compose([\n",
        "        transforms.Resize((227, 227)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load Data\n",
        "    try:\n",
        "        train_ds = ChestXrayDataset(csv_train, img_dir, tf, mode=model_type)\n",
        "        val_ds = ChestXrayDataset(csv_val, img_dir, tf, mode=model_type)\n",
        "\n",
        "        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "        val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "        print(f\"Data Loaded: {len(train_ds)} Train | {len(val_ds)} Val\")\n",
        "        print(f\"Classes: {train_ds.classes}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Init Model\n",
        "    num_classes = len(train_ds.classes)\n",
        "    if model_type == 'dense':\n",
        "        print(\"Model: DenseNet121\")\n",
        "        model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "        model.classifier = nn.Linear(1024, num_classes)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        print(\"Model: AlexNet\")\n",
        "        model = models.alexnet(weights='IMAGENET1K_V1')\n",
        "        for param in model.features.parameters(): param.requires_grad = False\n",
        "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Loop\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # Train\n",
        "        for imgs, targets in train_loader:\n",
        "            imgs, targets = imgs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = 0; total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, targets in val_loader:\n",
        "                imgs, targets = imgs.to(DEVICE), targets.to(DEVICE)\n",
        "                outputs = model(imgs)\n",
        "\n",
        "                if model_type == 'dense':\n",
        "                    preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                    correct += (preds == targets).sum().item()\n",
        "                    total += targets.numel()\n",
        "                else:\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    correct += (preds == targets).sum().item()\n",
        "                    total += targets.size(0)\n",
        "\n",
        "        val_acc = correct / total * 100\n",
        "        print(f\"Epoch {epoch+1}: Loss={train_loss/len(train_loader):.4f} | Val Acc={val_acc:.2f}%\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            save_path = f\"/content/drive/MyDrive/DiaChestXR_Project/{model_type}_best.pth\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Saved Best Model: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "train_on_colab('alex', epochs=15)\n",
        "\n",
        "train_on_colab('dense', epochs=15)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
